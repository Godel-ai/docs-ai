# VSE

![](<images/2020-07-24-01-01-21 (1).png>)

![](images/2020-07-24-01-01-39.png)

![](<images/2020-07-24-01-01-59 (1).png>)

![](<images/2020-07-24-01-02-13 (1).png>)

![](images/2020-07-24-01-02-27.png)

![](<images/2020-07-24-01-02-50 (1).png>)

![](<images/2020-07-24-01-02-59 (1).png>)

![](<images/2020-07-24-01-04-26 (1).png>)

![](<images/2020-07-24-01-04-46 (1).png>)

![](images/2020-07-24-01-05-03.png)

![](images/2020-07-24-01-05-22.png)

![](<images/2020-07-24-01-06-46 (1).png>)

![](images/2020-07-24-01-07-02.png)

![](images/2020-07-24-01-07-48.png)

![](images/2020-07-24-01-08-05.png)

![](<images/2020-07-24-01-08-23 (1).png>)

![](images/2020-07-24-01-08-45.png)

![](images/2020-07-24-01-08-56.png)

![](images/2020-07-24-01-09-10.png)

![](<images/2020-07-24-01-09-32 (1).png>)

## Visual-NLP

* [**Interfacing vision and NLP - Google Docs**](https://docs.google.com/document/d/1MfQG6LdutZdOhELpfQSkMuxVMxsEUYtSQ7nS5WToyCU/edit?ts=5e7ca588)
* [**Expressing Objects just like Words: Recurrent Visual Embedding for Image-Text Matching**](https://arxiv.org/abs/2002.08510.pdf)
* [**Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models**](https://arxiv.org/abs/1411.2539.pdf)
* [**ACMM: Aligned Cross-Modal Memory for Few-Shot Image and Sentence Matching**](http://openaccess.thecvf.com/content\_ICCV\_2019/papers/Huang\_ACMM\_Aligned\_Cross-Modal\_Memory\_for\_Few-Shot\_Image\_and\_Sentence\_Matching\_ICCV\_2019\_paper.pdf)
* [**MultiGrain: a unified image embedding for classes and instances**](https://arxiv.org/abs/1902.05509.pdf)
* [**cross modal graph interface - Google Scholar**](https://scholar.google.com/scholar?start=20\&q=cross+modal+graph+interface\&hl=en\&as\_sdt=0,5\&as\_ylo=2020)
* [**Archive ouverte HAL - Review of Recent Deep Learning Based Methods for Image-Text Retrieval**](https://hal.archives-ouvertes.fr/hal-02480975/)
* [**Review of Recent Deep Learning Based Methods for Image-Text Retrieval**](https://hal.archives-ouvertes.fr/hal-02480975/document)
* [**Vision-Language Navigation Policy Learning and Adaptation - IEEE Journals & Magazine**](https://ieeexplore.ieee.org/abstract/document/8986691)
* [**\[2003.00392\] Fine-grained Video-Text Retrieval with Hierarchical Graph Reasoning**](https://arxiv.org/abs/2003.00392)
* [**Novel model to integrate word embeddings and syntactic trees for automatic caption generation from images**](https://link.springer.com/content/pdf/10.1007/s00500-019-03973-w.pdf)
* [**SimCLR Notebook.ipynb - Colaboratory**](https://colab.research.google.com/drive/1ObAYvVKQjMG5nd2wIno7j2y\_X91E9IrX#scrollTo=u067AY93zh-k\&forceEdit=true\&sandboxMode=true)
* [**Discriminative distribution alignment: A unified framework for heterogeneous domain adaptation - ScienceDirect**](https://www.sciencedirect.com/science/article/abs/pii/S0031320319304650)
* [**One Embedding To Do Them All**](https://arxiv.org/abs/1906.12120.pdf)
* [**\[1906.02390\] Multi-view Knowledge Graph Embedding for Entity Alignment**](https://arxiv.org/abs/1906.02390)
* [**\[1612.00222\] Interaction Networks for Learning about Objects, Relations and Physics**](https://arxiv.org/abs/1612.00222)
* [**\[1706.01433\] Visual Interaction Networks**](https://arxiv.org/abs/1706.01433)

## Unified Embedding Project

* [**Discriminative distribution alignment: A unified framework for heterogeneous domain adaptation - ScienceDirect**](https://www.sciencedirect.com/science/article/abs/pii/S0031320319304650)
* [**Differentiable Scene Graphs**](http://openaccess.thecvf.com/content\_WACV\_2020/papers/Raboh\_Differentiable\_Scene\_Graphs\_WACV\_2020\_paper.pdf)
* [**Expressing Objects just like Words: Recurrent Visual Embedding for Image-Text Matching**](https://arxiv.org/abs/2002.08510.pdf)
* [**ACMM: Aligned Cross-Modal Memory for Few-Shot Image and Sentence Matching**](http://openaccess.thecvf.com/content\_ICCV\_2019/papers/Huang\_ACMM\_Aligned\_Cross-Modal\_Memory\_for\_Few-Shot\_Image\_and\_Sentence\_Matching\_ICCV\_2019\_paper.pdf)
* [**Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models**](https://arxiv.org/abs/1411.2539.pdf)
* [**Cross-Modal Attention With Semantic Consistence for Image-Text Matching - IEEE Journals & Magazine**](https://ieeexplore.ieee.org/abstract/document/8994196)
* [**Multi-Modal Graph Neural Network for Joint Reasoning on Vision and Scene Text**](https://arxiv.org/abs/2003.13962.pdf)
* [**Visual Semantic Reasoning for Image-Text Matching**](http://openaccess.thecvf.com/content\_ICCV\_2019/papers/Li\_Visual\_Semantic\_Reasoning\_for\_Image-Text\_Matching\_ICCV\_2019\_paper.pdf)
* [**Visual Reasoning with Natural Language**](https://arxiv.org/abs/1710.00453.pdf)
* [**Explicit Reasoning over End-to-End Neural Architectures for Visual Question Answering**](https://arxiv.org/abs/1803.08896.pdf)
* [**PubLayNet: largest dataset ever for document layout analysis - Papers With Code**](https://paperswithcode.com/paper/190807836)
* [**HUSE: Hierarchical Universal Semantic Embeddings**](https://arxiv.org/abs/1911.05978v1.pdf)
* [**Cross-modal\_Scene\_Graph\_Matching\_for\_Relationship-aware\_Image-Text\_Retrieval**](http://openaccess.thecvf.com/content\_WACV\_2020/html/Wang\_Cross-modal\_Scene\_Graph\_Matching\_for\_Relationship-aware\_Image-Text\_Retrieval\_WACV\_2020\_paper.html)
* [**Cross-Modal Attention With Semantic Consistence for Image-Text Matching - IEEE Journals & Magazine**](https://ieeexplore.ieee.org/abstract/document/8994196)
* [**\[2002.08510\] Expressing Objects just like Words: Recurrent Visual Embedding for Image-Text Matching**](https://arxiv.org/abs/2002.08510)
* [**Novel model to integrate word embeddings and syntactic trees for automatic caption generation from images**](https://link.springer.com/article/10.1007/s00500-019-03973-w)
* [**\[2003.03772\] IMRAM: Iterative Matching with Recurrent Attention Memory for Cross-Modal Image-Text Retrieval**](https://arxiv.org/abs/2003.03772)
* [**Multi-Modal Memory Enhancement Attention Network for Image-Text Matching - IEEE Journals & Magazine**](https://ieeexplore.ieee.org/abstract/document/9006782)
* [**\[1906.02890\] Visually Grounded Neural Syntax Acquisition**](https://arxiv.org/abs/1906.02890)
* [**\[1911.09826\] Factorized Multimodal Transformer for Multimodal Sequential Learning**](https://arxiv.org/abs/1911.09826)
* [**MUREL: Multimodal Relational Reasoning for Visual Question Answering**](https://arxiv.org/abs/1902.09487.pdf)
* [**Relation-Aware Graph Attention Network for Visual Question Answering**](https://arxiv.org/abs/1903.12314.pdf)
