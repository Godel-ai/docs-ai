### Interpretable GAN Controls

https://arxiv.org/abs/2004.02546 | [2004.02546] GANSpace: Discovering Interpretable GAN Controls
https://github.com/harskish/ganspace | harskish/ganspace: Discovering Interpretable GAN Controls
https://paperswithcode.com/paper/improved-techniques-for-training-single-image | - Improved Techniques for Training Single-Image GANs
https://arxiv.org/abs/1907.07171.pdf | On the "steerability" of generative adversarial networks
https://github.com/facebookresearch/GAN-optimization-landscape | facebookresearch/GAN-optimization-landscape: code to reproduce the empirical results in the research paper
https://arxiv.org/abs/1906.10112.pdf | GANalyze: Toward Visual Definitions of Cognitive Image Properties
https://paperswithcode.com/paper/mimicry-towards-the-reproducibility-of-gan-1 | Mimicry: Towards the Reproducibility of GAN Research
https://paperswithcode.com/paper/token-manipulation-generative-adversarial | Token Manipulation Generative Adversarial Network for Text Generation

### Training and Stability of Gans

https://arxiv.org/abs/1701.04862.pdf | Towards Principled Methods for Training Generative Adversarial Networks
https://arxiv.org/abs/1704.00028.pdf | Improved Training of Wasserstein GANs
https://arxiv.org/abs/1705.07761.pdf | VEEGAN: Reducing Mode Collapse in GANs using Implicit Variational Learning
https://github.com/tamarott/SinGAN | tamarott/SinGAN: Official pytorch implementation of the paper: "SinGAN: Learning a Generative Model from a Single Natural Image"
https://arxiv.org/abs/1609.07152.pdf | Input Convex Neural Networks
http://www.jmlr.org/papers/volume20/18-444/18-444.pdf | Tunability: Importance of Hyperparameters of Machine Learning Algorithms
https://arxiv.org/abs/2004.13344 | [2004.13344] Robust Generative Adversarial Network
https://arxiv.org/abs/2006.04248.pdf | Learning Convex Optimization Models
http://openaccess.thecvf.com/content_CVPR_2019/papers/Cubuk_AutoAugment_Learning_Augmentation_Strategies_From_Data_CVPR_2019_paper.pdf | AutoAugment: Learning Augmentation Strategies From Data
https://library.oapen.org/bitstream/handle/20.500.12657/23012/1007149.pdf?sequence=1#page=15 | Automated
Machine Learning Book
http://proceedings.mlr.press/v108/lorraine20a/lorraine20a.pdf | Optimizing Millions of Hyperparameters by Implicit Differentiation
https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8870187 | Why is Developing Machine Learning Applications Challenging? A Study on Stack Overflow Posts
https://distill.pub/2019/gan-open-problems/ | Open Questions about Generative Adversarial Networks
https://datascience.stackexchange.com/questions/51276/gan-am-i-seeing-mode-collapse-common-fixes-not-working | machine learning - GAN - am I seeing mode collapse? Common fixes not working - Data Science Stack Exchange
https://poloclub.github.io/ganlab/ | GAN Lab: Play with Generative Adversarial Networks in Your Browser!
https://arxiv.org/abs/1502.02127 | [1502.02127] Hyperparameter Search in Machine Learning
http://papers.nips.cc/paper/8808-learning-disentangled-representations-for-recommendation.pdf | Learning Disentangled Representations for Recommendation
https://www.google.com/search?q=learning+rate+scheduler+for+gans&oq=learning+rate+scheduler+for+gans&aqs=chrome..69i57j33.5185j0j7&sourceid=chrome&ie=UTF-8 | learning rate scheduler for gans - Google Search
https://arxiv.org/abs/1801.04406.pdf | Which Training Methods for GANs do actually Converge?
https://arxiv.org/abs/1905.00094.pdf | Forget the Learning Rate, Decay Loss
https://papers.nips.cc/paper/6797-stabilizing-training-of-generative-adversarial-networks-through-regularization.pdf | Stabilizing Training of Generative Adversarial Networks through Regularization
https://scholar.google.com/scholar?as_ylo=2019&hl=en&as_sdt=0,5&sciodt=0,5&cites=11974368860899381464&scipsc= | Roth: Stabilizing training of generative adversarial... - Google Scholar
http://papers.nips.cc/paper/8454-multi-marginal-wasserstein-gan | Multi-marginal Wasserstein GAN
http://proceedings.mlr.press/v97/kurach19a.html | A Large-Scale Study on Regularization and Normalization in GANs
http://papers.nips.cc/paper/9377-a-domain-agnostic-measure-for-monitoring-and-evaluating-gans | A Domain Agnostic Measure for Monitoring and Evaluating GANs
https://arxiv.org/abs/1902.03984 | [1902.03984] Improving Generalization and Stability of Generative Adversarial Networks
https://arxiv.org/abs/2001.06937 | [2001.06937] A Review on Generative Adversarial Networks: Algorithms, Theory, and Applications
https://towardsdatascience.com/10-lessons-i-learned-training-generative-adversarial-networks-gans-for-a-year-c9071159628 | 10 Lessons I Learned Training GANs for one Year - Towards Data Science
https://scholar.google.com/scholar?start=10&hl=en&as_sdt=0,5&sciodt=0,5&as_ylo=2020&cites=3068694056154618633&scipsc= | Gulrajani: Improved training of wasserstein gans - Google Scholar
https://arxiv.org/abs/1704.00028.pdf | Improved Training of Wasserstein GANs
https://arxiv.org/abs/1802.05957 | [1802.05957] Spectral Normalization for Generative Adversarial Networks
http://openaccess.thecvf.com/content_CVPR_2019/html/Karras_A_Style-Based_Generator_Architecture_for_Generative_Adversarial_Networks_CVPR_2019_paper.html | CVPR 2019 Open Access Repository
http://proceedings.mlr.press/v97/zhang19d.html | Self-Attention Generative Adversarial Networks
http://openaccess.thecvf.com/content_CVPR_2020/html/Shen_Interpreting_the_Latent_Space_of_GANs_for_Semantic_Face_Editing_CVPR_2020_paper.html | Interpreting_the_Latent_Space_of_GANs_for_Semantic_Face_Editing
http://openaccess.thecvf.com/content_CVPR_2020/html/Karnewar_MSG-GAN_Multi-Scale_Gradients_for_Generative_Adversarial_Networks_CVPR_2020_paper.html | CVPR 2020 Open Access Repository
https://arxiv.org/abs/1906.04848.pdf | A Closer Look at the Optimization Landscapes of Generative Adversarial Networks
https://arxiv.org/abs/1910.13540v1.pdf |Small-GAN: Speeding Up GAN Training Using Core-sets
https://www.google.com/search?safe=active&sxsrf=ACYBGNRdeNkjXLyKnFPprGxJDVUmhbAkSw%3A1568476766141&ei=Xg59XZOiCMXevgSpyoXICw&q=common+mistakes+in+training+gans&oq=common+mistakes+in+training+gans&gs_l=psy-ab.3..33i22i29i30.11244.15333..15478...3.2..0.317.2580.0j15j0j1......0....1..gws-wiz.......0i71j35i39j0i67j0j0i22i30j33i21j33i160.b4czx-_BCKg&ved=0ahUKEwiTye-j19DkAhVFr48KHSllAbkQ4dUDCAs&uact=5 | common mistakes in training gans - Google Search
https://medium.com/@utk.is.here/keep-calm-and-train-a-gan-pitfalls-and-tips-on-training-generative-adversarial-networks-edd529764aa9 | Keep Calm and train a GAN. Pitfalls and Tips on training Generative Adversarial Networks
https://medium.com/intel-student-ambassadors/tips-on-training-your-gans-faster-and-achieve-better-results-9200354acaa5 | Tips On Training Your GANs Faster and Achieve Better Results
https://machinelearningmastery.com/how-to-code-generative-adversarial-network-hacks/ | How to Implement GAN Hacks in Keras to Train Stable Models
https://papers.nips.cc/paper/6125-improved-techniques-for-training-gans.pdf | Improved Techniques for Training GANs
https://towardsdatascience.com/10-lessons-i-learned-training-generative-adversarial-networks-gans-for-a-year-c9071159628 | 10 Lessons I Learned Training GANs for one Year - Towards Data Science
https://machinelearningmastery.com/how-to-code-generative-adversarial-network-hacks/ | How to Implement GAN Hacks in Keras to Train Stable Models
https://machinelearningmastery.com/how-to-train-stable-generative-adversarial-networks/ | Tips for Training Stable Generative Adversarial Networks
https://machinelearningmastery.com/generative_adversarial_networks/ | Generative Adversarial Networks with Python

### GANs

https://www.google.com/search?q=faster+training+of+gans+with+high+fidelity+synthesis&rlz=1C1CHBF_enUS858US858&oq=faster+training+of+gans+with+high+fidelity+synthesis&aqs=chrome..69i57.21806j0j7&sourceid=chrome&ie=UTF-8 | faster training of gans with high fidelity synthesis - Google Search
https://scholar.google.com/scholar?start=0&hl=en&as_sdt=0,5&sciodt=0,5&as_ylo=2020&cites=11486098150916361186&scipsc= | Karras: Progressive growing of gans for improved... - Google Scholar
https://arxiv.org/abs/2002.08988.pdf | BlockGAN Learning 3D Object-aware Scene Representations from Unlabelled Images
https://arxiv.org/abs/2004.10634v1.pdf | Unpaired Photo-to-manga Translation Based on The Methodology of Manga Drawing
http://openaccess.thecvf.com/content_ECCV_2018/papers/Bo_Zhao_Modular_Generative_Adversarial_ECCV_2018_paper.pdf | Modular Generative Adversarial Networks
https://people.eecs.berkeley.edu/~ke.li/projects/imle/scene_layouts/ | Diverse Image Synthesis from Semantic Layouts via Conditional IMLE
https://arxiv.org/abs/1811.07441.pdf | CompoNet: Learning to Generate the Unseen by Part Synthesis and Composition
https://www.google.com/search?q=how+to+view+gan+output&oq=how+to+view+gan+output&aqs=chrome..69i57.5406j0j7&sourceid=chrome&ie=UTF-8 | how to view gan output - Google Search
https://towardsdatascience.com/a-new-way-to-look-at-gans-7c6b6e6e9737 | A New Way to look at GANs - Towards Data Science
https://towardsdatascience.com/graduating-in-gans-going-from-understanding-generative-adversarial-networks-to-running-your-own-39804c283399 | Graduating in GANs: Going from understanding generative adversarial networks to running your own
https://medium.com/comet-ml/this-machine-learning-medium-post-does-not-exist-c4705215b4a0 | This Machine Learning Medium post does not exist - Comet.ml - Medium
https://towardsdatascience.com/gan-objective-functions-gans-and-their-variations-ad77340bce3c | GAN Objective Functions: GANs and Their Variations - Towards Data Science
https://papers.nips.cc/paper/8315-the-point-where-reality-meets-fantasy-mixed-adversarial-generators-for-image-splice-detection.pdf | The Point Where Reality Meets Fantasy: Mixed Adversarial Generators for Image Splice Detection
https://arxiv.org/abs/1809.11096.pdf | Large Scale GAN Training for High Fidelity Natural Image Synthesis
https://arxiv.org/abs/1610.07629.pdf | Modulating early visual processing by language
https://arxiv.org/abs/1707.00683.pdf | A Learned Representation For Artistic Style
https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Vondrick_Anticipating_Visual_Representations_CVPR_2016_paper.pdf | Anticipating Visual Representations From Unlabeled Video
https://arxiv.org/abs/1909.05483v1.pdf | 3D Ken Burns Effect from a Single Image
https://github.com/sergeytulyakov/mocogan | sergeytulyakov/mocogan: MoCoGAN: Decomposing Motion and Content for Video Generation
https://arxiv.org/abs/1907.06571 | [1907.06571] Efficient Video Generation on Complex Datasets
https://arxiv.org/abs/1904.01766 | [1904.01766] VideoBERT: A Joint Model for Video and Language Representation Learning
https://arxiv.org/abs/1903.12161 | [1903.12161] Fast video object segmentation with Spatio-Temporal GANs
https://link.springer.com/article/10.1007/s11263-019-01210-3 | GANimation: One-Shot Anatomically Consistent Facial Animation | SpringerLink
http://openaccess.thecvf.com/content_CVPR_2019/html/Li_StoryGAN_A_Sequential_Conditional_GAN_for_Story_Visualization_CVPR_2019_paper.html | CVPR 2019 Open Access Repository
http://openaccess.thecvf.com/content_CVPR_2019/html/Nam_End-To-End_Time-Lapse_Video_Synthesis_From_a_Single_Outdoor_Image_CVPR_2019_paper.html | CVPR 2019 Open Access Repository
https://arxiv.org/abs/1908.06607 | [1908.06607] Video synthesis of human upper body with realistic face
https://scholar.google.com/scholar?cites=13583776322979873311&as_sdt=2005&sciodt=0,5&hl=en | Liu: Video synthesis of human upper body with realistic face - Google Scholar
https://www.sciencedirect.com/science/article/abs/pii/S0097849319300147 | Cartoonish sketch-based face editing in videos using identity deformation transfer - ScienceDirect
https://arxiv.org/abs/1905.12043 | [1905.12043] Video-to-Video Translation for Visual Speech Synthesis
https://arxiv.org/abs/1904.12356 | [1904.12356] Deferred Neural Rendering: Image Synthesis using Neural Textures
https://arxiv.org/abs/1811.09393 | [1811.09393] Temporally Coherent GANs for Video Super-Resolution (TecoGAN)
https://arxiv.org/abs/1905.02320 | [1905.02320] Spatially Constrained Generative Adversarial Networks for Conditional Image Generation
http://openaccess.thecvf.com/content_CVPRW_2019/html/MBCCV/Sidorov_Changing_the_Image_Memorability_From_Basic_Photo_Editing_to_GANs_CVPRW_2019_paper.html | CVPR 2019 Open Access Repository
https://arxiv.org/abs/1909.07957 | [1909.07957] An Internal Learning Approach to Video Inpainting
https://arxiv.org/abs/1901.02212 | [1901.02212] FakeCatcher: Detection of Synthetic Portrait Videos using Biological Signals
https://arxiv.org/abs/1908.09514.pdf | https://arxiv.org/abs/1908.09514.pdf
http://openaccess.thecvf.com/content_CVPR_2019/papers/Nam_End-To-End_Time-Lapse_Video_Synthesis_From_a_Single_Outdoor_Image_CVPR_2019_paper.pdf | End-To-End Time-Lapse Video Synthesis From a Single Outdoor Image
https://arxiv.org/abs/1808.06601.pdf | 1808.06601.pdf
https://arxiv.org/abs/1905.08233.pdf | 1905.08233.pdf
http://openaccess.thecvf.com/content_CVPR_2019/papers/Rhodin_Neural_Scene_Decomposition_for_Multi-Person_Motion_Capture_CVPR_2019_paper.pdf | Neural Scene Decomposition for Multi-Person Motion Capture
https://arxiv.org/abs/1904.10247.pdf | 1904.10247.pdf
https://arxiv.org/abs/1904.08379.pdf | https://arxiv.org/abs/1904.08379.pdf
https://arxiv.org/abs/1907.06571.pdf | https://arxiv.org/abs/1907.06571.pdf
https://arxiv.org/abs/1906.01292.pdf | https://arxiv.org/abs/1906.01292.pdf
https://arxiv.org/abs/1906.07889.pdf | https://arxiv.org/abs/1906.07889.pdf
https://arxiv.org/abs/1904.10247.pdf | 1904.10247.pdf
https://www.citi.sinica.edu.tw/papers/yylin/6497-F.pdf | Deep Video Frame Interpolation using Cyclic Frame Generation
http://openaccess.thecvf.com/content_ECCV_2018/papers/Fitsum_Reda_SDC-Net_Video_prediction_ECCV_2018_paper.pdf | SDC-Net: Video prediction using spatially-displaced convolution
https://arxiv.org/abs/1712.00080.pdf | https://arxiv.org/abs/1712.00080.pdf
https://openreview.net/forum?id=rylgEULtdN | FVD: A new Metric for Video Generation | OpenReview
https://openreview.net/forum?id=rylgEULtdN | pdf
http://openaccess.thecvf.com/content_CVPR_2019/papers/Lee_Inserting_Videos_Into_Videos_CVPR_2019_paper.pdf | Inserting Videos Into Videos
https://arxiv.org/abs/1805.01934.pdf | Learning to See in the Dark
https://arxiv.org/abs/1805.08318.pdf | Self-Attention Generative Adversarial Networks
http://sci-hub.tw/https://dl.acm.org/citation.cfm?id=3073640 | Sci-Hub | Synthesizing Obama. ACM Transactions on Graphics, 36(4), 1–13 | 10.1145/3072959.3073640
https://web.stanford.edu/~zollhoef/papers/EG18_RecoSTAR/paper.pdf | State of the Art on 3D Reconstruction with RGB-D Cameras
http://people.csail.mit.edu/sumner/research/deftransfer/Sumner2004DTF.pdf | Sumner2004DTF.pdf
https://web.stanford.edu/~zollhoef/papers/CVPR2016_Face2Face/paper.pdf | Face2Face: Real-time Face Capture and Reenactment of RGB Videos
http://kunzhou.net/2012/facewarehouse-tr.pdf | facewarehouse-tr.pdf
https://web.stanford.edu/~zollhoef/papers/CVPR2016_Face2Face/supple.pdf | supple.pdf
https://www.google.com/search?safe=active&rlz=1C1CHBF_enUS858US858&sxsrf=ACYBGNQnqyOClsDOWxo8ySwkTiLt_X3gQg%3A1568994509704&ei=zfSEXanFKv_bz7sP49ajoAU&q=face2face%3A+real-time+face+capture+and+reenactment+of+rgb+videos+github&oq=Face2Face%3A+Real-time+Face+Capture+and+Reenactment+of+RGB+Videos&gs_l=psy-ab.1.0.0i71l8.0.0..2611...0.2..0.0.0.......0......gws-wiz.39Vgoctz3ZA | face2face: real-time face capture and reenactment of rgb videos github - Google Search
https://gist.github.com/iwanao731 | iwanao731’s gists
https://google.github.io/tacotron/publications/uncovering_latent_style_factors_for_expressive_speech_synthesis/index.html | Audio samples from "Uncovering Latent Style Factors for Expressive Speech Synthesis"
https://github.com/karaninder/Face2Face | karaninder/Face2Face: A software which takes images of two people and can takes the expressions of person in 1st photo and mimics the same expression in the 2nd image.
https://github.com/datitran/face2face-demo | datitran/face2face-demo: pix2pix demo that learns from facial landmarks and translates this into a face
https://github.com/GordonRen/pose2pose | GordonRen/pose2pose: This is a pix2pix demo that learns from pose and translates this into a human. A webcam-enabled application is also provided that translates your pose to the trained pose. Everybody dance now !
https://github.com/ESanchezLozano/GANnotation | ESanchezLozano/GANnotation: GANnotation (PyTorch): Landmark-guided face to face synthesis using GANs (And a triple consistency loss!)
https://github.com/ESanchezLozano/StarGAN-with-Triple-Consistency-Loss | ESanchezLozano/StarGAN-with-Triple-Consistency-Loss: StarGAN with a triple consistency loss
https://arxiv.org/abs/1811.03492.pdf | 1811.03492.pdf
https://github.com/datitran/face2face-demo | datitran/face2face-demo: pix2pix demo that learns from facial landmarks and translates this into a face
https://towardsdatascience.com/face2face-a-pix2pix-demo-that-mimics-the-facial-expression-of-the-german-chancellor-b6771d65bf66 | Face2face — A Pix2Pix demo that mimics the facial expression of the German chancellor
https://arxiv.org/abs/1805.11729.pdf | HeadOn: Real-time Reenactment of Human Portrait Videos
https://en.wikipedia.org/wiki/Iteratively_reweighted_least_squares | Iteratively reweighted least squares - Wikipedia
http://openaccess.thecvf.com/content_cvpr_2018/papers/Dong_Style_Aggregated_Network_CVPR_2018_paper.pdf | Style Aggregated Network for Facial Landmark Detection
http://sci-hub.tw/https://dl.acm.org/citation.cfm?id=3073640 | Sci-Hub | Synthesizing Obama. ACM Transactions on Graphics, 36(4), 1–13 | 10.1145/3072959.3073640
http://openaccess.thecvf.com/content_ICCV_2017_workshops/w19/html/Tewari_MoFA_Model-Based_Deep_ICCV_2017_paper.html | ICCV 2017 Open Access Repository
http://openaccess.thecvf.com/content_cvpr_2017/html/Shu_Neural_Face_Editing_CVPR_2017_paper.html | CVPR 2017 Open Access Repository
https://dl.acm.org/citation.cfm?id=3201283 | Deep video portraits
http://openaccess.thecvf.com/content_cvpr_2018/html/Sengupta_SfSNet_Learning_Shape_CVPR_2018_paper.html | CVPR 2018 Open Access Repository
https://dl.acm.org/citation.cfm?id=3130818 | Bringing portraits to life
https://arxiv.org/abs/1812.01874.pdf | 1812.01874.pdf

https://www.google.com/search?safe=active&rlz=1C1CHBF_enUS858US858&sxsrf=ACYBGNQnqyOClsDOWxo8ySwkTiLt_X3gQg%3A1568994509704&ei=zfSEXanFKv_bz7sP49ajoAU&q=face2face%3A+real-time+face+capture+and+reenactment+of+rgb+videos+github&oq=Face2Face%3A+Real-time+Face+Capture+and+Reenactment+of+RGB+Videos&gs_l=psy-ab.1.0.0i71l8.0.0..2611...0.2..0.0.0.......0......gws-wiz.39Vgoctz3ZA | face2face: real-time face capture and reenactment of rgb videos github - Google Search
https://google.github.io/tacotron/publications/uncovering_latent_style_factors_for_expressive_speech_synthesis/index.html | Audio samples from "Uncovering Latent Style Factors for Expressive Speech Synthesis"
https://github.com/GordonRen/pose2pose | GordonRen/pose2pose: This is a pix2pix demo that learns from pose and translates this into a human. A webcam-enabled application is also provided that translates your pose to the trained pose. Everybody dance now !
https://github.com/ESanchezLozano/GANnotation | ESanchezLozano/GANnotation: GANnotation (PyTorch): Landmark-guided face to face synthesis using GANs (And a triple consistency loss!)
https://github.com/ESanchezLozano/StarGAN-with-Triple-Consistency-Loss | ESanchezLozano/StarGAN-with-Triple-Consistency-Loss: StarGAN with a triple consistency loss
https://arxiv.org/abs/1811.03492.pdf | 1811.03492.pdf
https://github.com/datitran/face2face-demo | datitran/face2face-demo: pix2pix demo that learns from facial landmarks and translates this into a face
https://towardsdatascience.com/face2face-a-pix2pix-demo-that-mimics-the-facial-expression-of-the-german-chancellor-b6771d65bf66 | Face2face — A Pix2Pix demo that mimics the facial expression of the German chancellor
https://arxiv.org/abs/1805.11729.pdf | HeadOn: Real-time Reenactment of Human Portrait Videos
http://openaccess.thecvf.com/content_ICCV_2017_workshops/w19/html/Tewari_MoFA_Model-Based_Deep_ICCV_2017_paper.html | ICCV 2017 Open Access Repository
https://dl.acm.org/citation.cfm?id=3201283 | Deep video portraits
https://arxiv.org/abs/1812.01874.pdf | Learning to Take Directions One Step at a Time
https://arxiv.org/abs/1802.05957.pdf | Spectral Normalization for Generative Adversarial Networks
https://arxiv.org/abs/1803.04477.pdf | 1803.04477.pdf
http://proceedings.mlr.press/v97/byrd19a/byrd19a.pdf | byrd19a.pdf
https://arxiv.org/abs/1808.04926.pdf | How Much Reading Does Reading Comprehension Require? A Critical Investigation of Popular Benchmarks
https://arxiv.org/abs/1803.04477.pdf | What is the Effect of Importance Weighting in Deep Learning?

http://openaccess.thecvf.com/content_ECCV_2018/papers/Bo_Zhao_Modular_Generative_Adversarial_ECCV_2018_paper.pdf | Modular Generative Adversarial Networks
https://arxiv.org/abs/1808.07371.pdf | 1808.07371.pdf
https://arxiv.org/abs/1903.07291.pdf | 1903.07291.pdf
http://openaccess.thecvf.com/content_CVPR_2019/papers/Karras_A_Style-Based_Generator_Architecture_for_Generative_Adversarial_Networks_CVPR_2019_paper.pdf | A Style-Based Generator Architecture for Generative Adversarial Networks
https://arxiv.org/abs/1809.11096.pdf | 1809.11096.pdf
http://openaccess.thecvf.com/content_cvpr_2018/papers/Yu_Generative_Image_Inpainting_CVPR_2018_paper.pdf | Generative Image Inpainting With Contextual Attention
https://arxiv.org/abs/1811.10597.pdf | 1811.10597.pdf
https://arxiv.org/abs/1909.05829.pdf | 1909.05829.pdf

https://arxiv.org/abs/1812.02734.pdf | 1812.02734.pdf

https://dblp1.uni-trier.de/db/conf/siggraph/siggraph2019posters.html | dblp: SIGGRAPH 2019 Posters
https://scholar.google.com/scholar?as_ylo=2019&hl=en&as_sdt=2005&sciodt=0,5&cites=3120460092236365926&scipsc= | Wang: Video-to-video synthesis - Google Scholar
https://arxiv.org/abs/1808.06601.pdf | 1808.06601.pdf
http://openaccess.thecvf.com/content_CVPR_2019/papers/Nam_End-To-End_Time-Lapse_Video_Synthesis_From_a_Single_Outdoor_Image_CVPR_2019_paper.pdf | End-To-End Time-Lapse Video Synthesis From a Single Outdoor Image
https://arxiv.org/abs/1905.08233.pdf | 1905.08233.pdf
http://openaccess.thecvf.com/content_CVPR_2019/papers/Kaneko_Label-Noise_Robust_Generative_Adversarial_Networks_CVPR_2019_paper.pdf | Label-Noise Robust Generative Adversarial Networks
http://openaccess.thecvf.com/content_CVPR_2019/papers/Meshry_Neural_Rerendering_in_the_Wild_CVPR_2019_paper.pdf | Neural Rerendering in the Wild
http://openaccess.thecvf.com/content_CVPR_2019/papers/Park_Adversarial_Inference_for_Multi-Sentence_Video_Description_CVPR_2019_paper.pdf | Adversarial Inference for Multi-Sentence Video Description
https://arxiv.org/abs/1908.09514.pdf | Mocycle-GAN: Unpaired Video-to-Video Translation
http://openaccess.thecvf.com/content_CVPR_2019/papers/Grigorev_Coordinate-Based_Texture_Inpainting_for_Pose-Guided_Human_Image_Generation_CVPR_2019_paper.pdf | Coordinate-Based Texture Inpainting for Pose-Guided Human Image Generation
http://openaccess.thecvf.com/content_CVPR_2019/papers/Rhodin_Neural_Scene_Decomposition_for_Multi-Person_Motion_Capture_CVPR_2019_paper.pdf | Neural Scene Decomposition for Multi-Person Motion Capture
https://arxiv.org/abs/1904.10247.pdf | 1904.10247.pdf
https://openreview.net/forum?id=rylgEULtdN | FVD: A new Metric for Video Generation | OpenReview
https://openreview.net/forum?id=rylgEULtdN | pdf
https://arxiv.org/abs/1906.07889.pdf | 1906.07889.pdf
https://arxiv.org/abs/1906.08240.pdf | Neural Point-Based Graphics
https://arxiv.org/abs/1904.08379.pdf | 1904.08379.pdf
https://arxiv.org/abs/1907.06571.pdf | 1907.06571.pdf
https://arxiv.org/abs/1906.01292.pdf | 1906.01292.pdf
http://sci-hub.tw/https://dl.acm.org/citation.cfm?id=3323006 | Sci-Hub | Stylizing video by example. ACM Transactions on Graphics, 38(4), 1–11 | 10.1145/3306346.3323006

https://arxiv.org/abs/1801.00055.pdf | 1801.00055.pdf
https://arxiv.org/abs/1803.08887 | [1803.08887] Dist-GAN: An Improved GAN using Distance Constraints
https://arxiv.org/abs/1809.11096.pdf | 1809.11096.pdf
https://arxiv.org/abs/1712.00080.pdf | 1712.00080.pdf
http://openaccess.thecvf.com/content_CVPR_2019/papers/Bao_Depth-Aware_Video_Frame_Interpolation_CVPR_2019_paper.pdf | Depth-Aware Video Frame Interpolation
http://openaccess.thecvf.com/content_ECCV_2018/papers/Fitsum_Reda_SDC-Net_Video_prediction_ECCV_2018_paper.pdf | SDC-Net: Video prediction using spatially-displaced convolution
https://arxiv.org/abs/1812.01717.pdf | 1812.01717.pdf
https://www.citi.sinica.edu.tw/papers/yylin/6497-F.pdf | Deep Video Frame Interpolation using Cyclic Frame Generation
https://arxiv.org/abs/1907.13622 | [1907.13622] Video Stitching for Linear Camera Arrays
https://arxiv.org/abs/1902.04394.pdf | Net2Vis: Transforming Deep Convolutional Networks into Publication-Ready Visualizations
https://www.youtube.com/watch?v=BQZ5xKd5kis&list=PLzGR8_vFq07KBRXNT8SmuhBUp1tHRsglm&index=12 | CVPR 2019 Oral Session 1-2C: Scenes & Representation - YouTube

https://www.youtube.com/watch?v=9GR8V-VR4Qg&list=PLzGR8_vFq07KBRXNT8SmuhBUp1tHRsglm&index=14 | CVPR 2019 Oral Session 1-2B: Synthesis - YouTube
https://arxiv.org/abs/1801.00055.pdf | 1801.00055.pdf
https://paperswithcode.com/area/computer-vision | Browse state-of-the-art in ML
https://arxiv.org/abs/1907.10830v1.pdf | 1907.10830v1.pdf
https://papers.nips.cc/paper/6644-pose-guided-person-image-generation.pdf | Pose Guided Person Image Generation
http://openaccess.thecvf.com/content_cvpr_2018/papers/Siarohin_Deformable_GANs_for_CVPR_2018_paper.pdf | Deformable GANs for Pose-Based Human Image Generation
https://arxiv.org/abs/1903.02271.pdf | High-Fidelity Image Generation With Fewer Labels

https://arxiv.org/abs/1906.04728 | [1906.04728] Shapes and Context: In-the-Wild Image Synthesis & Manipulation
https://arxiv.org/abs/1711.10485.pdf | 1711.10485.pdf
http://openaccess.thecvf.com/content_cvpr_2018/papers/Zhang_Photographic_Text-to-Image_Synthesis_CVPR_2018_paper.pdf | Photographic Text-to-Image Synthesis With a Hierarchically-Nested Adversarial Network
http://openaccess.thecvf.com/content_ECCV_2018/papers/Bo_Zhao_Modular_Generative_Adversarial_ECCV_2018_paper.pdf | Modular Generative Adversarial Networks
https://arxiv.org/abs/1905.01680.pdf | Learning Character-Agnostic Motion for Motion Retargeting in 2D
https://arxiv.org/abs/1805.06485.pdf | 1805.06485.pdf
http://openaccess.thecvf.com/content_CVPR_2019/papers/Kanazawa_Learning_3D_Human_Dynamics_From_Video_CVPR_2019_paper.pdf | Learning 3D Human Dynamics From Video
http://openaccess.thecvf.com/content_cvpr_2018/papers/Villegas_Neural_Kinematic_Networks_CVPR_2018_paper.pdf | Neural Kinematic Networks for Unsupervised Motion Retargetting
https://www.youtube.com/watch?v=9GR8V-VR4Qg&list=PLzGR8_vFq07KBRXNT8SmuhBUp1tHRsglm&index=14 | CVPR 2019 Oral Session 1-2B: Synthesis - YouTube
https://www.youtube.com/watch?v=qStuhkIHE6c | CVPR18: Tutorial: Part 2: Generative Adversarial Networks - YouTube
https://www.youtube.com/watch?v=F-85-1lU6DM | [NeurIPS 2018] How to Start Training: The Effect of Initialization and Architecture - YouTube
https://www.youtube.com/watch?v=EXLRZr0k8ok&list=PL_bDvITUYucD54Ym5XKGqTv9xNsrOX0aS&index=25 | CVPR18: Tutorial: Part 1: Generative Adversarial Networks - YouTube
https://scholar.google.com/citations?hl=en&user=d97bGd8AAAAJ&view_op=list_works&sortby=pubdate | Alexei A. Efros - Google Scholar Citations

https://arxiv.org/abs/1808.06601.pdf | 1808.06601.pdf
https://arxiv.org/abs/1808.07371.pdf | 1808.07371.pdf
https://arxiv.org/abs/1902.05611.pdf | 1902.05611.pdf
http://openaccess.thecvf.com/content_CVPR_2019/papers/Lee_Inserting_Videos_Into_Videos_CVPR_2019_paper.pdf | Inserting Videos Into Videos
https://arxiv.org/abs/1904.07846.pdf | 1904.07846.pdf
https://arxiv.org/abs/1903.07291.pdf | 1903.07291.pdf
https://arxiv.org/abs/1711.11585.pdf | 1711.11585.pdf
https://arxiv.org/abs/1710.10196.pdf | 1710.10196.pdf
http://openaccess.thecvf.com/content_ECCV_2018/papers/Xun_Huang_Multimodal_Unsupervised_Image-to-image_ECCV_2018_paper.pdf | Multimodal Unsupervised Image-to-image Translation
http://openaccess.thecvf.com/content_CVPR_2019/papers/Karras_A_Style-Based_Generator_Architecture_for_Generative_Adversarial_Networks_CVPR_2019_paper.pdf | A Style-Based Generator Architecture for Generative Adversarial Networks
http://openaccess.thecvf.com/content_ECCV_2018/papers/Hsin-Ying_Lee_Diverse_Image-to-Image_Translation_ECCV_2018_paper.pdf | Diverse Image-to-Image Translation via Disentangled Representations
http://openaccess.thecvf.com/content_cvpr_2018/papers/Zhang_Densely_Connected_Pyramid_CVPR_2018_paper.pdf | Densely Connected Pyramid Dehazing Network
http://sci-hub.tw/https://dl.acm.org/citation.cfm?id=3201283 | Sci-Hub | Deep video portraits. ACM Transactions on Graphics, 37(4), 1–14 | 10.1145/3197517.3201283
http://sci-hub.tw/https://ieeexplore.ieee.org/abstract/document/8358814 | Sci-Hub | Perceptual Adversarial Networks for Image-to-Image Transformation. IEEE Transactions on Image Processing, 27(8), 4066–4079 | 10.1109/TIP.2018.2836316
http://openaccess.thecvf.com/content_cvpr_2018/papers/Choi_StarGAN_Unified_Generative_CVPR_2018_paper.pdf | StarGAN: Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation
https://arxiv.org/abs/1805.08318.pdf | Self-Attention Generative Adversarial Networks
https://arxiv.org/abs/1809.11096.pdf | 1809.11096.pdf
http://papers.nips.cc/paper/8224-glow-generative-flow-with-invertible-1x1-convolutions | Glow: Generative Flow with Invertible 1x1 Convolutions
http://openaccess.thecvf.com/content_cvpr_2018/papers/Zhang_Residual_Dense_Network_CVPR_2018_paper.pdf | Residual Dense Network for Image Super-Resolution
http://openaccess.thecvf.com/content_cvpr_2018/papers/Yu_Generative_Image_Inpainting_CVPR_2018_paper.pdf | Generative Image Inpainting With Contextual Attention
http://sci-hub.tw/https://ieeexplore.ieee.org/abstract/document/8411144 | Sci-Hub | StackGAN++: Realistic Image Synthesis with Stacked Generative Adversarial Networks. IEEE Transactions on Pattern Analysis and Machine Intelligence, 1–1 | 10.1109/TPAMI.2018.2856256
https://arxiv.org/abs/1705.01908.pdf | 1705.01908.pdf
http://openaccess.thecvf.com/content_ECCV_2018/papers/Tanmay_Gupta_Imagine_This_Scripts_ECCV_2018_paper.pdf | Imagine This! Scripts to Compositions to Videos
https://ieeexplore.ieee.org/abstract/document/8022768 | Automatic manga colorization with color style by generative adversarial nets - IEEE Conference Publication
http://sci-hub.tw/https://science.sciencemag.org/content/360/6394/1204.abstract | Sci-Hub | Neural scene representation and rendering. Science, 360(6394), 1204–1210 | 10.1126/science.aar6170
https://arxiv.org/abs/1801.04406.pdf | Which Training Methods for GANs do actually Converge?
https://arxiv.org/abs/1811.10597.pdf | 1811.10597.pdf
http://openaccess.thecvf.com/content_CVPR_2019/papers/Kim_Deep_Video_Inpainting_CVPR_2019_paper.pdf | Deep Video Inpainting
https://arxiv.org/abs/1907.10719.pdf | 1907.10719.pdf
https://arxiv.org/abs/1905.01723.pdf | 1905.01723.pdf
https://github.com/NVlabs/SPADE | NVlabs/SPADE: Semantic Image Synthesis with SPADE
https://github.com/NVIDIA/pix2pixHD | NVIDIA/pix2pixHD: Synthesizing and manipulating 2048x1024 images with conditional GANs
http://papers.nips.cc/paper/7423-pacgan-the-power-of-two-samples-in-generative-adversarial-networks.pdf | PacGAN: The power of two samples in generative adversarial networks
http://papers.nips.cc/paper/8224-glow-generative-flow-with-invertible-1x1-convolutions.pdf | Glow: Generative Flow with Invertible 1x1 Convolutions
https://arxiv.org/abs/1810.01367.pdf | 1810.01367.pdf
https://arxiv.org/abs/1703.10593.pdf | 1703.10593.pdf
http://papers.nips.cc/paper/6672-unsupervised-image-to-image-translation-networks.pdf | Unsupervised Image-to-Image Translation Networks
http://openaccess.thecvf.com/content_ICCV_2017/papers/Yi_DualGAN_Unsupervised_Dual_ICCV_2017_paper.pdf | DualGAN: Unsupervised Dual Learning for Image-To-Image Translation
http://openaccess.thecvf.com/content_cvpr_2018/papers/Wang_High-Resolution_Image_Synthesis_CVPR_2018_paper.pdf | High-Resolution Image Synthesis and Semantic Manipulation With Conditional GANs
https://arxiv.org/abs/1711.03213.pdf | 1711.03213.pdf
http://papers.nips.cc/paper/6650-toward-multimodal-image-to-image-translation.pdf | Toward Multimodal Image-to-Image Translation
https://arxiv.org/abs/1808.03240.pdf | User-Guided Deep Anime Line Art Colorization with Conditional Adversarial Networks
http://proceedings.mlr.press/v48/reed16.pdf | Generative Adversarial Text to Image Synthesis
http://openaccess.thecvf.com/content_cvpr_2017/html/Huang_Stacked_Generative_Adversarial_CVPR_2017_paper.html | CVPR 2017 Open Access Repository
http://openaccess.thecvf.com/content_iccv_2017/html/Liang_Dual_Motion_GAN_ICCV_2017_paper.html | ICCV 2017 Open Access Repository
https://arxiv.org/abs/1609.07093.pdf | 1609.07093.pdf
http://papers.nips.cc/paper/6657-marrnet-3d-shape-reconstruction-via-25d-sketches.pdf | MarrNet: 3D Shape Reconstruction via 2.5D Sketches
https://www.youtube.com/watch?v=9GR8V-VR4Qg | CVPR 2019 Oral Session 1-2B: Synthesis - YouTube
https://www.youtube.com/watch?v=GRQuRcpf5Gc | AI-Based Video-to-Video Synthesis - YouTube
https://www.youtube.com/watch?v=7otKtmT-vjI | Video Frame Synthesis using Deep Voxel Flow (ICCV 2017 oral) - YouTube
https://www.youtube.com/channel/UC0n76gicaarsN_Y9YShWwhw | ComputerVisionFoundation Videos - YouTube
https://www.youtube.com/watch?v=qStuhkIHE6c | CVPR18: Tutorial: Part 2: Generative Adversarial Networks - YouTube
https://www.youtube.com/channel/UC0n76gicaarsN_Y9YShWwhw | ComputerVisionFoundation Videos - YouTube
https://arxiv.org/abs/1909.01066v2.pdf | 1909.01066v2.pdf
https://arxiv.org/abs/1907.02253v1.pdf | 1907.02253v1.pdf
https://arxiv.org/abs/1907.07587.pdf | 1907.07587.pdf
https://arxiv.org/abs/1904.07846.pdf | 1904.07846.pdf
http://www.vision.ee.ethz.ch/ntire18/talks/Ming-YuLiu_pix2pixHD_NTIRE2018talk.pdf | pix2pixHD_ntire2018
https://arxiv.org/abs/1808.06601 | [1808.06601] Video-to-Video Synthesis
https://dl.acm.org/citation.cfm?id=3201283 | Deep video portraits
http://papers.nips.cc/paper/8240-context-aware-synthesis-and-placement-of-object-instances | Context-aware Synthesis and Placement of Object Instances
https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.13632 | Deep Video‐Based Performance Cloning - Aberman - 2019 - Computer Graphics Forum - Wiley Online Library
http://openaccess.thecvf.com/content_CVPR_2019/html/Kim_Deep_Video_Inpainting_CVPR_2019_paper.html | CVPR 2019 Open Access Repository
http://openaccess.thecvf.com/content_CVPR_2019/html/Nam_End-To-End_Time-Lapse_Video_Synthesis_From_a_Single_Outdoor_Image_CVPR_2019_paper.html | CVPR 2019 Open Access Repository
http://openaccess.thecvf.com/content_CVPR_2019/html/Lee_Inserting_Videos_Into_Videos_CVPR_2019_paper.html | CVPR 2019 Open Access Repository
https://www.sciencedirect.com/science/article/pii/S1742287618304146 | A review of digital video tampering: From simple editing to full synthesis - ScienceDirect