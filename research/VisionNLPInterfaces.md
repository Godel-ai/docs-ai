## Vision-NLP Interfaces

---

### Neuro Symbolic VQA (: Using different Neural Modules for VQA)

---

![](images/2020-07-24-01-01-03.png)

![](images/2020-07-24-01-01-21.png)

![](images/2020-07-24-01-01-39.png)

---

![](images/2020-07-24-01-01-59.png)

![](images/2020-07-24-01-02-13.png)

![](images/2020-07-24-01-02-27.png)

![](images/2020-07-24-01-02-50.png)

---

![](images/2020-07-24-01-02-59.png)

![](images/2020-07-24-01-04-26.png)

![](images/2020-07-24-01-04-46.png)

---

![](images/2020-07-24-01-05-03.png)

![](images/2020-07-24-01-05-22.png)

![](images/2020-07-24-01-06-46.png)

![](images/2020-07-24-01-07-02.png)

---

![](images/2020-07-24-01-07-48.png)

![](images/2020-07-24-01-08-05.png)

![](images/2020-07-24-01-08-23.png)

![](images/2020-07-24-01-08-45.png)

---

![](images/2020-07-24-01-08-56.png)

![](images/2020-07-24-01-09-10.png)

---

![](images/2020-07-24-01-09-32.png)

---

### Visual-NLP

- https://docs.google.com/document/d/1MfQG6LdutZdOhELpfQSkMuxVMxsEUYtSQ7nS5WToyCU/edit?ts=5e7ca588 | Interfacing vision and NLP - Google Docs
- https://arxiv.org/abs/2002.08510.pdf | Expressing Objects just like Words: Recurrent Visual Embedding for Image-Text Matching
- https://arxiv.org/abs/1411.2539.pdf | Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models
- http://openaccess.thecvf.com/content_ICCV_2019/papers/Huang_ACMM_Aligned_Cross-Modal_Memory_for_Few-Shot_Image_and_Sentence_Matching_ICCV_2019_paper.pdf | ACMM: Aligned Cross-Modal Memory for Few-Shot Image and Sentence Matching
- https://arxiv.org/abs/1902.05509.pdf | MultiGrain: a unified image embedding for classes and instances
- https://scholar.google.com/scholar?start=20&q=cross+modal+graph+interface&hl=en&as_sdt=0,5&as_ylo=2020 | cross modal graph interface - Google Scholar
- https://hal.archives-ouvertes.fr/hal-02480975/ | Archive ouverte HAL - Review of Recent Deep Learning Based Methods for Image-Text Retrieval
- https://hal.archives-ouvertes.fr/hal-02480975/document | Review of Recent Deep Learning Based Methods for Image-Text Retrieval
- https://ieeexplore.ieee.org/abstract/document/8986691 | Vision-Language Navigation Policy Learning and Adaptation - IEEE Journals & Magazine
- https://arxiv.org/abs/2003.00392.pdf | 2003.00392.pdf
- https://link.springer.com/content/pdf/10.1007/s00500-019-03973-w.pdf | Novel model to integrate word embeddings and syntactic trees for automatic caption generation from images
- https://colab.research.google.com/drive/1ObAYvVKQjMG5nd2wIno7j2y_X91E9IrX#scrollTo=u067AY93zh-k&forceEdit=true&sandboxMode=true | SimCLR Notebook.ipynb - Colaboratory
- http://localhost:8889/tree#notebooks | Home
- https://www.sciencedirect.com/science/article/abs/pii/S0031320319304650 | Discriminative distribution alignment: A unified framework for heterogeneous domain adaptation - ScienceDirect
- https://arxiv.org/abs/1906.12120.pdf | One Embedding To Do Them All
- https://arxiv.org/abs/1906.02390 | [1906.02390] Multi-view Knowledge Graph Embedding for Entity Alignment
- https://arxiv.org/abs/1612.00222 | [1612.00222] Interaction Networks for Learning about Objects, Relations and Physics
- https://arxiv.org/abs/1706.01433 | [1706.01433] Visual Interaction Networks

---

### Unified Embedding Project

- https://github.com/GemsLab/KGist | Knowledge Graph summarization for anomaly/error detection & completion
- https://www.sciencedirect.com/science/article/abs/pii/S0031320319304650 | Discriminative distribution alignment: A unified framework for heterogeneous domain adaptation - ScienceDirect
- http://openaccess.thecvf.com/content_WACV_2020/papers/Raboh_Differentiable_Scene_Graphs_WACV_2020_paper.pdf | Differentiable Scene Graphs
- https://arxiv.org/abs/2002.08510.pdf | Expressing Objects just like Words: Recurrent Visual Embedding for Image-Text Matching
- http://openaccess.thecvf.com/content_ICCV_2019/papers/Huang_ACMM_Aligned_Cross-Modal_Memory_for_Few-Shot_Image_and_Sentence_Matching_ICCV_2019_paper.pdf | ACMM: Aligned Cross-Modal Memory for Few-Shot Image and Sentence Matching
- https://arxiv.org/abs/1411.2539.pdf | Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models
- https://ieeexplore.ieee.org/abstract/document/8994196 | Cross-Modal Attention With Semantic Consistence for Image-Text Matching - IEEE Journals & Magazine
- https://arxiv.org/abs/2003.13962.pdf | Multi-Modal Graph Neural Network for Joint Reasoning on Vision and Scene Text

* http://openaccess.thecvf.com/content_ICCV_2019/papers/Li_Visual_Semantic_Reasoning_for_Image-Text_Matching_ICCV_2019_paper.pdf | Visual Semantic Reasoning for Image-Text Matching
* https://arxiv.org/abs/1710.00453.pdf | Visual Reasoning with Natural Language
* https://arxiv.org/abs/1803.08896.pdf | Explicit Reasoning over End-to-End Neural Architectures for Visual Question Answering
* https://paperswithcode.com/paper/190807836 | PubLayNet: largest dataset ever for document layout analysis - Papers With Code
* https://arxiv.org/abs/1911.05978v1.pdf | HUSE: Hierarchical Universal Semantic Embeddings
* http://openaccess.thecvf.com/content_WACV_2020/html/Wang_Cross-modal_Scene_Graph_Matching_for_Relationship-aware_Image-Text_Retrieval_WACV_2020_paper.html | WACV 2020 Open Access Repository
* https://ieeexplore.ieee.org/abstract/document/8994196 | Cross-Modal Attention With Semantic Consistence for Image-Text Matching - IEEE Journals & Magazine
* https://arxiv.org/abs/2002.08510 | [2002.08510] Expressing Objects just like Words: Recurrent Visual Embedding for Image-Text Matching
* https://link.springer.com/article/10.1007/s00500-019-03973-w | Novel model to integrate word embeddings and syntactic trees for automatic caption generation from images | SpringerLink
* https://arxiv.org/abs/2003.03772 | [2003.03772] IMRAM: Iterative Matching with Recurrent Attention Memory for Cross-Modal Image-Text Retrieval
* https://ieeexplore.ieee.org/abstract/document/9006782 | Multi-Modal Memory Enhancement Attention Network for Image-Text Matching - IEEE Journals & Magazine
* https://arxiv.org/abs/1906.02890 | [1906.02890] Visually Grounded Neural Syntax Acquisition
* https://arxiv.org/abs/1911.09826 | [1911.09826] Factorized Multimodal Transformer for Multimodal Sequential Learning
* https://arxiv.org/abs/1902.09487.pdf | MUREL: Multimodal Relational Reasoning for Visual Question Answering
* https://arxiv.org/abs/1903.12314.pdf | Relation-Aware Graph Attention Network for Visual Question Answering
