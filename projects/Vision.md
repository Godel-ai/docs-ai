# Computer Vision

## AI as a Movie Maker

### SPADE

* [**junyanz/pytorch-CycleGAN-and-pix2pix: Image-to-Image Translation in PyTorch**](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix)
* [**NVlabs/SPADE: Semantic Image Synthesis with SPADE**](https://github.com/NVlabs/SPADE)

![](images/2020-07-22-01-11-48.png)

![](images/2020-07-22-01-12-18.png)

![](<images/2020-07-22-01-13-07 (1).png>)

![](images/2020-07-22-01-13-30.png)

![](images/2020-07-22-01-14-19.png)

![](images/2020-07-22-01-16-12.png)

![](images/2020-07-22-01-17-57.png)

![](<images/2020-07-22-02-02-42 (1).png>)

[**Link**](https://arxiv.org/pdf/1711.07971.pdf)

### End-to-End Object Detection with Transformers

[https://github.com/facebookresearch/detr](https://github.com/facebookresearch/detr)

* [**Learning Spatial Common Sense With Geometry-Aware Recurrent Networks**](http://openaccess.thecvf.com/content\_CVPR\_2019/html/Tung\_Learning\_Spatial\_Common\_Sense\_With\_Geometry-Aware\_Recurrent\_Networks\_CVPR\_2019\_paper.html)
* [**Probabilistic Future Prediction for Video Scene Understanding**](https://arxiv.org/abs/2003.06409v1)
* [**Learning and Using the Arrow of Time**](http://openaccess.thecvf.com/content\_cvpr\_2018/papers/Wei\_Learning\_and\_Using\_CVPR\_2018\_paper.pdf)
* [**guoyongcs/DRN: Closed-loop Matters: Dual Regression Networks for Single Image Super-Resolution**](https://github.com/guoyongcs/DRN)
* [**Closed-loop Matters: Dual Regression Networks for Single Image Super-Resolution**](https://arxiv.org/abs/2003.07018.pdf)
* [**Ariel Shamir's Homepage**](http://www.faculty.idc.ac.il/arik/site/writeVideo.asp)
* [**Non-Photorealistic Computer Graphics: Modeling, Rendering, and Animation - Thomas Strothotte, Stefan Schlechtweg - Google Books**](https://books.google.co.in/books?hl=en\&lr=\&id=Kq\_dU65kngUC\&oi=fnd\&pg=PP2\&ots=vEmD9Rjr3i\&sig=LXVandqs4l0nLWDwDaNgSwa3XjY\&redir\_esc=y#v=onepage\&q\&f=false)
* [**Lin: Video stylization: painterly rendering and optimizat... - Google Scholar**](https://scholar.google.com/scholar?um=1\&ie=UTF-8\&lr\&cites=1538375253694513701)
* [**Generalizing Convolutional Neural Networks for Equivariance to Lie Groups on Arbitrary Continuous Data**](https://github.com/mfinzi/LieConv)
* [**What Synthesis is Missing: Depth Adaptation Integrated with Weak Supervision for Indoor Scene Parsing**](https://arxiv.org/abs/1903.09781.pdf)
* [**Mocycle-GAN: Unpaired Video-to-Video Translation**](https://arxiv.org/abs/1908.09514.pdf)
* [**End-To-End Time-Lapse Video Synthesis From a Single Outdoor Image**](http://openaccess.thecvf.com/content\_CVPR\_2019/papers/Nam\_End-To-End\_Time-Lapse\_Video\_Synthesis\_From\_a\_Single\_Outdoor\_Image\_CVPR\_2019\_paper.pdf)
* [**Deep Video Frame Interpolation using Cyclic Frame Generation**](https://www.citi.sinica.edu.tw/papers/yylin/6497-F.pdf)
* [**FVD: A new Metric for Video Generation**](https://openreview.net/forum?id=rylgEULtdN)
* [**Semantic Image Synthesis with Spatially-Adaptive Normalization**](https://arxiv.org/abs/1903.07291.pdf)
* [**Modular Generative Adversarial Networks**](http://openaccess.thecvf.com/content\_ECCV\_2018/papers/Bo\_Zhao\_Modular\_Generative\_Adversarial\_ECCV\_2018\_paper.pdf)
* [**Unsupervised Doodling and Painting with Improved SPIRAL**](https://learning-to-paint.github.io)
* [**Image Synthesis From Reconfigurable Layout and Style**](https://arxiv.org/abs/1908.07500.pdf)
* [**Adversarial Learning of Semantic Relevance in Text to Image Synthesis**](http://www.eecs.harvard.edu/\~htk/publication/2019-aaai-cha-gwon-kung.pdf)
* [**Convolutional Sequence Generation for Skeleton-Based Action Synthesis - Google Search**](https://www.google.com/search?q=Convolutional+Sequence+Generation+for+Skeleton-Based+Action+Synthesis\&rlz=1C1CHBF\_enUS858US858\&oq=Convolutional+Sequence+Generation+for+Skeleton-Based+Action+Synthesis\&aqs=chrome..69i57\&sourceid=chrome\&ie=UTF-8)
* [**Text-based Editing of Talking-head Video**](https://arxiv.org/abs/1906.01524.pdf)
* [**Incremental Scene Synthesis**](https://arxiv.org/abs/1811.12297.pdf)
* [**Unsupervised Person Image Generation With Semantic Parsing Transformation**](http://openaccess.thecvf.com/content\_CVPR\_2019/papers/Song\_Unsupervised\_Person\_Image\_Generation\_With\_Semantic\_Parsing\_Transformation\_CVPR\_2019\_paper.pdf)
* [**DeepView: View Synthesis With Learned Gradient Descent**](http://openaccess.thecvf.com/content\_CVPR\_2019/papers/Flynn\_DeepView\_View\_Synthesis\_With\_Learned\_Gradient\_Descent\_CVPR\_2019\_paper.pdf)
* [**Textured Neural Avatars**](http://openaccess.thecvf.com/content\_CVPR\_2019/papers/Shysheya\_Textured\_Neural\_Avatars\_CVPR\_2019\_paper.pdf)
* [**Multi-Channel Attention Selection GAN With Cascaded Semantic Guidance for Cross-View Image Translation**](http://openaccess.thecvf.com/content\_CVPR\_2019/papers/Tang\_Multi-Channel\_Attention\_Selection\_GAN\_With\_Cascaded\_Semantic\_Guidance\_for\_Cross-View\_CVPR\_2019\_paper.pdf)
* [**STGAN: A Unified Selective Transfer Network for Arbitrary Image Attribute Editing**](http://openaccess.thecvf.com/content\_CVPR\_2019/papers/Liu\_STGAN\_A\_Unified\_Selective\_Transfer\_Network\_for\_Arbitrary\_Image\_Attribute\_CVPR\_2019\_paper.pdf)
* [**Towards Instance-Level Image-To-Image Translation**](http://openaccess.thecvf.com/content\_CVPR\_2019/papers/Shen\_Towards\_Instance-Level\_Image-To-Image\_Translation\_CVPR\_2019\_paper.pdf)
* [**Deep Flow-Guided Video Inpainting**](http://openaccess.thecvf.com/content\_CVPR\_2019/papers/Xu\_Deep\_Flow-Guided\_Video\_Inpainting\_CVPR\_2019\_paper.pdf)

## Vision

* [**\[2001.07966\] ImageBERT: Cross-modal Pre-training with Large-scale Weak-supervised Image-Text Data**](https://arxiv.org/abs/2001.07966)
* [**\[2001.09518\] Unsupervised Disentanglement of Pose, Appearance and Background from Images and Videos**](https://arxiv.org/abs/2001.09518)
* [**Everybody’s Talkin’: Let Me Talk as You Want**](https://wywu.github.io/projects/EBT/EBT.html)
* [**\[2001.09908\] Rotation, Translation, and Cropping for Zero-Shot Generalization**](https://arxiv.org/abs/2001.09908)
* [**https://next.cs.cmu.edu/multiverse/**](https://next.cs.cmu.edu/multiverse/)
* [**\[1804.03160\] The Sound of Pixels**](https://arxiv.org/abs/1804.03160)
* [**Google AI Blog: AutoFlip: An Open Source Framework for Intelligent Video Reframing**](https://ai.googleblog.com/2020/02/autoflip-open-source-framework-for.html?m=1)
* [**\[2002.05709\] A Simple Framework for Contrastive Learning of Visual Representations**](https://arxiv.org/abs/2002.05709)
* [**\[2002.05235v1\] Image-to-Image Translation with Text Guidance**](https://arxiv.org/abs/2002.05235v1)
* [**\[2001.06232\] Sideways: Depth-Parallel Training of Video Models**](https://arxiv.org/abs/2001.06232)
* [**Deep Single Image Portrait Relighting**](https://zhhoper.github.io/dpr.html)
* [**\[1910.05852v2\] Implicit competitive regularization in GANs**](https://arxiv.org/abs/1910.05852v2)
* [**\[2004.04572v1\] ARCH: Animatable Reconstruction of Clothed Humans**](https://arxiv.org/abs/2004.04572v1)
* [**\[2004.05155\] Learning to Explore using Active Neural SLAM**](https://arxiv.org/abs/2004.05155)
* [**\[2004.13060v1\] GIMP-ML: Python Plugins for using Computer Vision Models in GIMP**](https://arxiv.org/abs/2004.13060v1)
* [**\[2004.12992v1\] MakeItTalk: Speaker-Aware Talking Head Animation**](https://arxiv.org/abs/2004.12992v1)
* [**\[1912.08795\] Dreaming to Distill: Data-free Knowledge Transfer via DeepInversion**](https://arxiv.org/abs/1912.08795)
* [**\[1912.11370\] Big Transfer (BiT): General Visual Representation Learning**](https://arxiv.org/abs/1912.11370)
* [**\[2005.07781\] Scones: Towards Conversational Authoring of Sketches**](https://arxiv.org/abs/2005.07781)
* [**\[2006.03677\] Visual Transformers: Token-based Image Representation and Processing for Computer Vision**](https://arxiv.org/abs/2006.03677)
* [**\[2006.09965v1\] High-Fidelity Generative Image Compression**](https://arxiv.org/abs/2006.09965v1)
* [**\[2006.10738v1\] Differentiable Augmentation for Data-Efficient GAN Training**](https://arxiv.org/abs/2006.10738v1)
* [**Image GPT**](https://openai.com/blog/image-gpt/)
* [**CVPR'20 Online Tutorial on Interpretable Machine Learning in Computer Vision**](https://interpretablevision.github.io)
* [**Consistent Video Depth Estimation**](https://roxanneluo.github.io/Consistent-Video-Depth-Estimation/)
* [**How to Get a Better GAN (Almost) for Free: Introducing the Metropolis-Hastings GAN** ](https://eng.uber.com/mh-gan/)
* [**Satoshi Iizuka — DeepRemaster**](http://iizuka.cs.tsukuba.ac.jp/projects/remastering/en/index.html)
* [**Use the Force, Luke!**](https://ehsanik.github.io/forcecvpr2020/)
* [**Generating Digital Painting Lighting Effects via RGB-space Geometry**](https://lllyasviel.github.io/PaintingLight/)
* [ **A deep learning approach for generalized speech animation**](https://dl.acm.org/doi/pdf/10.1145/3072959.3073699)
* [**Synthesizing Environment-Aware Activities via Activity Sketches**](https://andrewliao11.github.io/project/env-program/)
* [**Feedback\_Adversarial\_Learning\_Spatial\_Feedback\_for\_Improving\_Generative\_Adversarial\_Networks**](https://openaccess.thecvf.com/content\_CVPR\_2019/papers/Huh\_Feedback\_Adversarial\_Learning\_Spatial\_Feedback\_for\_Improving\_Generative\_Adversarial\_Networks\_CVPR\_2019\_paper.pdf)
* [**Penrose: from mathematical notation to beautiful diagrams**](https://penrose.ink/siggraph20.html)
* [**High Fidelity Generative Image Compression**](https://hific.github.io)
* [**Immersive Light Field Video with a Layered Mesh Representation**](https://augmentedperception.github.io/deepviewvideo/)
* [**Introducing neural supersampling for real-time rendering - Facebook Research**](https://research.fb.com/blog/2020/07/introducing-neural-supersampling-for-real-time-rendering/)
* [**Swapping Autoencoder for Deep Image Manipulation**](https://taesung.me/SwappingAutoencoder/)
* [**The Eyes Have It: An Integrated Eye and Face Model for Photorealistic Facial Animation - Facebook Research**](https://research.fb.com/publications/the-eyes-have-it-an-integrated-eye-and-face-model-for-photorealistic-facial-animation/)
* [**Neural Supersampling for Real-time Rendering - Facebook Research**](https://research.fb.com/publications/neural-supersampling-for-real-time-rendering/)
* [**VR Facial Animation via Multiview Image Translation - Facebook Research**](https://research.fb.com/publications/vr-facial-animation-via-multiview-image-translation/)
* [**VirtualHome**](http://virtual-home.org)
* [**Reinforcing an Image Caption Generator Using Off-Line Human Feedback**](https://arxiv.org/abs/1911.09753.pdf)
* [**HobbitLong/CMC: pytorch implementation of "Contrastive Multiview Coding", "Momentum Contrast for Unsupervised Visual Representation Learning", and "Unsupervised Feature Learning via Non-Parametric Instance-level Discrimination"**](https://github.com/HobbitLong/CMC)
* [**Deep Learning Monitor - Find new Arxiv papers, tweets and Reddit posts for you**](https://deeplearn.org)
